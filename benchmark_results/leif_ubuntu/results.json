{
  "model_type": "leif",
  "n_params": 15354744,
  "vocab_size": 26296,
  "test_loss": 4.23007554843508,
  "test_perplexity": 68.72242384930922,
  "history": [
    {
      "epoch": 1,
      "train_loss": 6.672552782913734,
      "val_loss": 6.139531209551055,
      "val_perplexity": 463.8360779607383,
      "time": 19.02199697494507
    },
    {
      "epoch": 2,
      "train_loss": 5.938532230302031,
      "val_loss": 5.834492083253531,
      "val_perplexity": 341.8910377588353,
      "time": 24.289571285247803
    },
    {
      "epoch": 3,
      "train_loss": 5.678308919145556,
      "val_loss": 5.666112620255043,
      "val_perplexity": 288.90924864100293,
      "time": 22.775646924972534
    },
    {
      "epoch": 4,
      "train_loss": 5.483980150645589,
      "val_loss": 5.531565773076024,
      "val_perplexity": 252.53902041577868,
      "time": 22.4577419757843
    },
    {
      "epoch": 5,
      "train_loss": 5.310863945871739,
      "val_loss": 5.41799204925011,
      "val_perplexity": 225.42602340119666,
      "time": 22.78158211708069
    },
    {
      "epoch": 6,
      "train_loss": 5.138374901757452,
      "val_loss": 5.292302320743429,
      "val_perplexity": 198.8006016732765,
      "time": 22.575007915496826
    },
    {
      "epoch": 7,
      "train_loss": 4.961620943886893,
      "val_loss": 5.178869230993863,
      "val_perplexity": 177.48200633101044,
      "time": 20.7994601726532
    },
    {
      "epoch": 8,
      "train_loss": 4.781223623623402,
      "val_loss": 5.077203290215854,
      "val_perplexity": 160.3250457216387,
      "time": 20.876821041107178
    },
    {
      "epoch": 9,
      "train_loss": 4.602206108018096,
      "val_loss": 4.980966091156006,
      "val_perplexity": 145.61499107697486,
      "time": 19.97907304763794
    },
    {
      "epoch": 10,
      "train_loss": 4.423684634598605,
      "val_loss": 4.896038211625198,
      "val_perplexity": 133.7588044970933,
      "time": 20.08444905281067
    },
    {
      "epoch": 11,
      "train_loss": 4.243837189791825,
      "val_loss": 4.807109397033165,
      "val_perplexity": 122.37736139311515,
      "time": 20.18092107772827
    },
    {
      "epoch": 12,
      "train_loss": 4.068718497976294,
      "val_loss": 4.731289066117386,
      "val_perplexity": 113.44170199092773,
      "time": 21.029875993728638
    },
    {
      "epoch": 13,
      "train_loss": 3.901473936776222,
      "val_loss": 4.6435287738668505,
      "val_perplexity": 103.9103776098646,
      "time": 20.36421012878418
    },
    {
      "epoch": 14,
      "train_loss": 3.7378875070017545,
      "val_loss": 4.570355974394699,
      "val_perplexity": 96.57848312153584,
      "time": 21.570988178253174
    },
    {
      "epoch": 15,
      "train_loss": 3.5869121081723367,
      "val_loss": 4.511077342362239,
      "val_perplexity": 91.01982522117393,
      "time": 21.418643951416016
    },
    {
      "epoch": 16,
      "train_loss": 3.4412778927187615,
      "val_loss": 4.432521931056319,
      "val_perplexity": 84.14335328931513,
      "time": 21.80052089691162
    },
    {
      "epoch": 17,
      "train_loss": 3.3020197476072264,
      "val_loss": 4.387538852362797,
      "val_perplexity": 80.44219503309766,
      "time": 21.885095834732056
    },
    {
      "epoch": 18,
      "train_loss": 3.180342856299114,
      "val_loss": 4.330170508088736,
      "val_perplexity": 75.95723678836787,
      "time": 23.175724029541016
    },
    {
      "epoch": 19,
      "train_loss": 3.0644725637482892,
      "val_loss": 4.284913585103792,
      "val_perplexity": 72.59627304928834,
      "time": 22.5107262134552
    },
    {
      "epoch": 20,
      "train_loss": 2.9523748952179707,
      "val_loss": 4.234044761493288,
      "val_perplexity": 68.99573985734453,
      "time": 22.368197202682495
    }
  ],
  "config": {
    "n_epochs": 20,
    "batch_size": 32,
    "learning_rate": 0.0006,
    "max_seq_len": 128,
    "seed": 42
  },
  "attention_density": 0.9817973292151163
}