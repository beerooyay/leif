{
  "model_type": "leif",
  "n_params": 7995993,
  "vocab_size": 7945,
  "test_loss": 5.541403452555339,
  "test_perplexity": 255.03567888202429,
  "history": [
    {
      "epoch": 1,
      "train_loss": 6.689388842809768,
      "val_loss": 5.944489081700643,
      "val_perplexity": 381.64432240927624,
      "time": 0.9847121238708496
    },
    {
      "epoch": 2,
      "train_loss": 5.583456516265869,
      "val_loss": 5.600508292516072,
      "val_perplexity": 270.5638980849719,
      "time": 0.6679379940032959
    },
    {
      "epoch": 3,
      "train_loss": 5.359529086521694,
      "val_loss": 5.572993516921997,
      "val_perplexity": 263.22087718627563,
      "time": 0.6684138774871826
    },
    {
      "epoch": 4,
      "train_loss": 5.276592754182362,
      "val_loss": 5.572855313618978,
      "val_perplexity": 263.1845017052885,
      "time": 0.6654682159423828
    },
    {
      "epoch": 5,
      "train_loss": 5.236748468308222,
      "val_loss": 5.570494651794434,
      "val_perplexity": 262.5639448499231,
      "time": 0.6659760475158691
    },
    {
      "epoch": 6,
      "train_loss": 5.18920510155814,
      "val_loss": 5.597853342692058,
      "val_perplexity": 269.8465172378304,
      "time": 0.6750259399414062
    },
    {
      "epoch": 7,
      "train_loss": 5.137175809769404,
      "val_loss": 5.5950658321380615,
      "val_perplexity": 269.09536463236327,
      "time": 0.665233850479126
    },
    {
      "epoch": 8,
      "train_loss": 5.128656682514009,
      "val_loss": 5.592153390248616,
      "val_perplexity": 268.31278018918704,
      "time": 0.6648960113525391
    },
    {
      "epoch": 9,
      "train_loss": 5.053084759485154,
      "val_loss": 5.5831724802653,
      "val_perplexity": 265.9138755601652,
      "time": 0.6618831157684326
    },
    {
      "epoch": 10,
      "train_loss": 5.012496721176874,
      "val_loss": 5.577053546905518,
      "val_perplexity": 264.29173422479647,
      "time": 0.6635499000549316
    },
    {
      "epoch": 11,
      "train_loss": 4.953793593815395,
      "val_loss": 5.574562390645345,
      "val_perplexity": 263.6341616146994,
      "time": 0.6676619052886963
    },
    {
      "epoch": 12,
      "train_loss": 4.897658370790028,
      "val_loss": 5.600529273351033,
      "val_perplexity": 270.56957480101494,
      "time": 0.6699068546295166
    },
    {
      "epoch": 13,
      "train_loss": 4.841515654609317,
      "val_loss": 5.589571634928386,
      "val_perplexity": 267.62095568652035,
      "time": 0.6728649139404297
    },
    {
      "epoch": 14,
      "train_loss": 4.782656033833821,
      "val_loss": 5.5998170375823975,
      "val_perplexity": 270.3769340828856,
      "time": 0.6708900928497314
    },
    {
      "epoch": 15,
      "train_loss": 4.7342475936526345,
      "val_loss": 5.618882417678833,
      "val_perplexity": 275.5812263648902,
      "time": 0.6709887981414795
    },
    {
      "epoch": 16,
      "train_loss": 4.672510169801258,
      "val_loss": 5.641022682189941,
      "val_perplexity": 281.7507126227394,
      "time": 0.669111967086792
    },
    {
      "epoch": 17,
      "train_loss": 4.6135406494140625,
      "val_loss": 5.644979079564412,
      "val_perplexity": 282.8676384466702,
      "time": 0.6671838760375977
    },
    {
      "epoch": 18,
      "train_loss": 4.558381807236445,
      "val_loss": 5.658940553665161,
      "val_perplexity": 286.84458507387706,
      "time": 0.6665687561035156
    },
    {
      "epoch": 19,
      "train_loss": 4.509060178484235,
      "val_loss": 5.67997940381368,
      "val_perplexity": 292.943396343644,
      "time": 0.66898512840271
    },
    {
      "epoch": 20,
      "train_loss": 4.444653397514706,
      "val_loss": 5.686291058858235,
      "val_perplexity": 294.79820129597965,
      "time": 0.6750431060791016
    }
  ],
  "config": {
    "n_epochs": 20,
    "batch_size": 16,
    "learning_rate": 0.0006,
    "max_seq_len": 128,
    "seed": 42
  },
  "attention_density": 0.9881449854651163
}