{
  "baseline": {
    "model_type": "baseline",
    "n_params": 4798003,
    "vocab_size": 51,
    "test_loss": 0.8216396886855364,
    "test_perplexity": 2.274225804304503,
    "history": [
      {
        "epoch": 1,
        "train_loss": 1.362985287899296,
        "val_loss": 0.9347116918790908,
        "val_perplexity": 2.546479181267473,
        "time": 9.559314966201782
      },
      {
        "epoch": 2,
        "train_loss": 0.9073568849258771,
        "val_loss": 0.8570492040543329,
        "val_perplexity": 2.35619776685231,
        "time": 9.320614099502563
      },
      {
        "epoch": 3,
        "train_loss": 0.8601833440397428,
        "val_loss": 0.8482931464437454,
        "val_perplexity": 2.335656823542165,
        "time": 9.604880094528198
      },
      {
        "epoch": 4,
        "train_loss": 0.8507099159776348,
        "val_loss": 0.8431543840302361,
        "val_perplexity": 2.3236852239937544,
        "time": 9.224162817001343
      },
      {
        "epoch": 5,
        "train_loss": 0.8454708827140669,
        "val_loss": 0.8395184562319801,
        "val_perplexity": 2.315251813220556,
        "time": 9.283336877822876
      },
      {
        "epoch": 6,
        "train_loss": 0.8407464775864937,
        "val_loss": 0.8361506774311974,
        "val_perplexity": 2.307467672235281,
        "time": 9.30182409286499
      },
      {
        "epoch": 7,
        "train_loss": 0.838246366749071,
        "val_loss": 0.8357180186680385,
        "val_perplexity": 2.306469542066635,
        "time": 9.28954815864563
      },
      {
        "epoch": 8,
        "train_loss": 0.836097729532686,
        "val_loss": 0.8351633719035557,
        "val_perplexity": 2.3051906209052784,
        "time": 9.576004266738892
      },
      {
        "epoch": 9,
        "train_loss": 0.8347700526725211,
        "val_loss": 0.833628891952454,
        "val_perplexity": 2.301656064660426,
        "time": 9.253283023834229
      },
      {
        "epoch": 10,
        "train_loss": 0.8336851893494662,
        "val_loss": 0.8330739518952748,
        "val_perplexity": 2.3003791378539833,
        "time": 9.442445993423462
      },
      {
        "epoch": 11,
        "train_loss": 0.8330204759014251,
        "val_loss": 0.8320987394877842,
        "val_perplexity": 2.2981368730967286,
        "time": 9.428417921066284
      },
      {
        "epoch": 12,
        "train_loss": 0.8317568895479316,
        "val_loss": 0.8313192110213022,
        "val_perplexity": 2.2963461080511247,
        "time": 10.252072095870972
      },
      {
        "epoch": 13,
        "train_loss": 0.8303141841605374,
        "val_loss": 0.8298308707418895,
        "val_perplexity": 2.2929309057650364,
        "time": 10.65193510055542
      },
      {
        "epoch": 14,
        "train_loss": 0.8275444229988203,
        "val_loss": 0.8257677630772666,
        "val_perplexity": 2.2836333818386794,
        "time": 11.163708925247192
      },
      {
        "epoch": 15,
        "train_loss": 0.824384801736161,
        "val_loss": 0.8247278389476594,
        "val_perplexity": 2.281259810762553,
        "time": 11.808195114135742
      },
      {
        "epoch": 16,
        "train_loss": 0.8226680752893561,
        "val_loss": 0.8227499288225931,
        "val_perplexity": 2.2767521432351083,
        "time": 12.350703001022339
      },
      {
        "epoch": 17,
        "train_loss": 0.8208988355175001,
        "val_loss": 0.8212081137157622,
        "val_perplexity": 2.2732445171364715,
        "time": 12.797654867172241
      },
      {
        "epoch": 18,
        "train_loss": 0.8194983694107021,
        "val_loss": 0.8214784169953967,
        "val_perplexity": 2.273859065638361,
        "time": 12.856411933898926
      },
      {
        "epoch": 19,
        "train_loss": 0.8189164255852024,
        "val_loss": 0.8200945012153141,
        "val_perplexity": 2.2707144126650687,
        "time": 12.163510084152222
      },
      {
        "epoch": 20,
        "train_loss": 0.8180419846212483,
        "val_loss": 0.8201342518367465,
        "val_perplexity": 2.270804676768083,
        "time": 11.696774244308472
      }
    ],
    "config": {
      "n_epochs": 20,
      "batch_size": 32,
      "learning_rate": 0.0001,
      "max_seq_len": 128,
      "seed": 42
    },
    "train_time": 0.014898061752319336
  }
}