{
  "model_type": "leif",
  "n_params": 15014152,
  "vocab_size": 25416,
  "test_loss": 5.194599211215973,
  "test_perplexity": 180.2958677528619,
  "history": [
    {
      "epoch": 1,
      "train_loss": 6.686267780931028,
      "val_loss": 6.171922880505758,
      "val_perplexity": 479.1064854369477,
      "time": 122.03120994567871
    },
    {
      "epoch": 2,
      "train_loss": 5.986838009803807,
      "val_loss": 5.884359965248714,
      "val_perplexity": 359.3726833673618,
      "time": 115.88699007034302
    },
    {
      "epoch": 3,
      "train_loss": 5.76540304210088,
      "val_loss": 5.754946776798794,
      "val_perplexity": 315.7487419181634,
      "time": 118.6678102016449
    },
    {
      "epoch": 4,
      "train_loss": 5.6167766645074435,
      "val_loss": 5.659539230286129,
      "val_perplexity": 287.0163636355859,
      "time": 105.35975790023804
    },
    {
      "epoch": 5,
      "train_loss": 5.493673111205776,
      "val_loss": 5.578186542268783,
      "val_perplexity": 264.5913452311127,
      "time": 113.1254210472107
    },
    {
      "epoch": 6,
      "train_loss": 5.3787502023183045,
      "val_loss": 5.501698698316302,
      "val_perplexity": 245.1079432761371,
      "time": 111.59591507911682
    },
    {
      "epoch": 7,
      "train_loss": 5.262769163471379,
      "val_loss": 5.435704420483302,
      "val_perplexity": 229.4544237566064,
      "time": 107.86924529075623
    },
    {
      "epoch": 8,
      "train_loss": 5.150579659361817,
      "val_loss": 5.368249756949289,
      "val_perplexity": 214.48713437152423,
      "time": 60.49956774711609
    },
    {
      "epoch": 9,
      "train_loss": 5.041595868324036,
      "val_loss": 5.311828219701374,
      "val_perplexity": 202.7205074348537,
      "time": 54.84372115135193
    },
    {
      "epoch": 10,
      "train_loss": 4.937700149675482,
      "val_loss": 5.264676245432051,
      "val_perplexity": 193.38368979843779,
      "time": 54.29975605010986
    },
    {
      "epoch": 11,
      "train_loss": 4.841452367773884,
      "val_loss": 5.23162453515189,
      "val_perplexity": 187.09650161292913,
      "time": 53.52013802528381
    },
    {
      "epoch": 12,
      "train_loss": 4.7497379093954,
      "val_loss": 5.210706324804397,
      "val_perplexity": 183.22342775164344,
      "time": 54.559725761413574
    },
    {
      "epoch": 13,
      "train_loss": 4.661508686466304,
      "val_loss": 5.188331959739564,
      "val_perplexity": 179.16944169420617,
      "time": 53.882545948028564
    },
    {
      "epoch": 14,
      "train_loss": 4.580457711328655,
      "val_loss": 5.188189990936764,
      "val_perplexity": 179.14400702857773,
      "time": 53.81168222427368
    },
    {
      "epoch": 15,
      "train_loss": 4.501473535685779,
      "val_loss": 5.18755072639102,
      "val_perplexity": 179.0295232129228,
      "time": 54.610560178756714
    },
    {
      "epoch": 16,
      "train_loss": 4.42561795831271,
      "val_loss": 5.187333583831787,
      "val_perplexity": 178.99065250446938,
      "time": 55.21072268486023
    },
    {
      "epoch": 17,
      "train_loss": 4.353316159008845,
      "val_loss": 5.197170325687954,
      "val_perplexity": 180.76002551334938,
      "time": 59.938777923583984
    },
    {
      "epoch": 18,
      "train_loss": 4.284687799950168,
      "val_loss": 5.21272934050787,
      "val_perplexity": 183.594466805603,
      "time": 56.11844825744629
    },
    {
      "epoch": 19,
      "train_loss": 4.2176662797797215,
      "val_loss": 5.222072419666109,
      "val_perplexity": 185.3178427242413,
      "time": 54.39380097389221
    },
    {
      "epoch": 20,
      "train_loss": 4.15627132920914,
      "val_loss": 5.244273549034482,
      "val_perplexity": 189.47811865842772,
      "time": 53.631916999816895
    }
  ],
  "config": {
    "n_epochs": 20,
    "batch_size": 16,
    "learning_rate": 0.0006,
    "max_seq_len": 512,
    "seed": 42
  },
  "attention_density": 0.5295943172819201
}