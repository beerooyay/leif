{
  "model_type": "baseline",
  "n_params": 8847625,
  "vocab_size": 7945,
  "test_loss": 5.469788710276286,
  "test_perplexity": 237.41002516278087,
  "history": [
    {
      "epoch": 1,
      "train_loss": 6.603837966918945,
      "val_loss": 5.800135612487793,
      "val_perplexity": 330.34435569205004,
      "time": 1.1614329814910889
    },
    {
      "epoch": 2,
      "train_loss": 5.436227094559443,
      "val_loss": 5.554113547007243,
      "val_perplexity": 258.29789406426227,
      "time": 0.6419272422790527
    },
    {
      "epoch": 3,
      "train_loss": 5.290214243389311,
      "val_loss": 5.565595308939616,
      "val_perplexity": 261.2807001575164,
      "time": 0.6425402164459229
    },
    {
      "epoch": 4,
      "train_loss": 5.276009945642381,
      "val_loss": 5.579607327779134,
      "val_perplexity": 264.96753996331034,
      "time": 0.6379809379577637
    },
    {
      "epoch": 5,
      "train_loss": 5.22297173454648,
      "val_loss": 5.573290904362996,
      "val_perplexity": 263.29916741004723,
      "time": 0.6454920768737793
    },
    {
      "epoch": 6,
      "train_loss": 5.144073327382405,
      "val_loss": 5.574373165766398,
      "val_perplexity": 263.58428019193366,
      "time": 0.6444008350372314
    },
    {
      "epoch": 7,
      "train_loss": 5.131819588797433,
      "val_loss": 5.5624057451883955,
      "val_perplexity": 260.44865634118537,
      "time": 0.6411380767822266
    },
    {
      "epoch": 8,
      "train_loss": 5.008325395129976,
      "val_loss": 5.548874378204346,
      "val_perplexity": 256.9481666081921,
      "time": 0.6374778747558594
    },
    {
      "epoch": 9,
      "train_loss": 4.8610058057875865,
      "val_loss": 5.505400101343791,
      "val_perplexity": 246.01686766947407,
      "time": 0.6402781009674072
    },
    {
      "epoch": 10,
      "train_loss": 4.672129017966134,
      "val_loss": 5.505746126174927,
      "val_perplexity": 246.1020103444563,
      "time": 0.6417441368103027
    },
    {
      "epoch": 11,
      "train_loss": 4.464591298784528,
      "val_loss": 5.571995258331299,
      "val_perplexity": 262.95824579320526,
      "time": 0.6460318565368652
    },
    {
      "epoch": 12,
      "train_loss": 4.285283701760428,
      "val_loss": 5.588415781656901,
      "val_perplexity": 267.311803830883,
      "time": 0.6486198902130127
    },
    {
      "epoch": 13,
      "train_loss": 4.052163918813069,
      "val_loss": 5.662915627161662,
      "val_perplexity": 287.9870826330996,
      "time": 0.6432662010192871
    },
    {
      "epoch": 14,
      "train_loss": 3.8215309324718656,
      "val_loss": 5.752131700515747,
      "val_perplexity": 314.861135050074,
      "time": 0.6470620632171631
    },
    {
      "epoch": 15,
      "train_loss": 3.5741190796806697,
      "val_loss": 5.854787190755208,
      "val_perplexity": 348.9006428706414,
      "time": 0.6443812847137451
    },
    {
      "epoch": 16,
      "train_loss": 3.3326927480243502,
      "val_loss": 5.930790662765503,
      "val_perplexity": 376.45204279993754,
      "time": 0.645697832107544
    },
    {
      "epoch": 17,
      "train_loss": 3.0939890997750417,
      "val_loss": 6.0840981006622314,
      "val_perplexity": 438.8238591968287,
      "time": 0.6446249485015869
    },
    {
      "epoch": 18,
      "train_loss": 2.8589466299329485,
      "val_loss": 6.20078984896342,
      "val_perplexity": 493.13839215661505,
      "time": 0.6451852321624756
    },
    {
      "epoch": 19,
      "train_loss": 2.631962549118769,
      "val_loss": 6.325243870417277,
      "val_perplexity": 558.4939972228894,
      "time": 0.6470198631286621
    },
    {
      "epoch": 20,
      "train_loss": 2.4329551401592435,
      "val_loss": 6.4209803740183515,
      "val_perplexity": 614.6053619916709,
      "time": 0.6485843658447266
    }
  ],
  "config": {
    "n_epochs": 20,
    "batch_size": 16,
    "learning_rate": 0.0006,
    "max_seq_len": 128,
    "seed": 42
  }
}